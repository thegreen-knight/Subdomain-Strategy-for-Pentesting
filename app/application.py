import socket
import requests
import re
import ssl

## Not in use
#def getDomainHostIP(domain):
    #IP = socket.gethostbyname(domain)

    #return IP

def subDomains(domain):
    subs = open("app/badsubs.txt", "r")
    prefixs = subs.readlines()
    subs.close()

    validDomains = open("validDomains.txt", "a")

    with open("bad_requests.txt", "a") as bad_requests:
        for prefix in prefixs:
            url = prefix.strip() + "." + domain
            cert = ["https://", "http://"]
            for x in cert:
                try:
                    url = x + url
                    web_response = requests.get(url, timeout=20)
                    print(url, web_response.status_code)
                    if web_response.status_code == 200:
                        validDomains.write(f"{url}\n")
                except requests.exceptions.RequestException as e:
                    bad_requests.write(f"{url} - {e}\n")
                    #print(f"Failed to request {url}: {e}")

def get_ssl_certificate(hostname):
    context = ssl.create_default_context()
    conn = context.wrap_socket(
        socket.socket(socket.AF_INET),
        server_hostname=hostname,
    )
    conn.settimeout(5.0)
    try:
        conn.connect((hostname, 443))
        ssl_info = conn.getpeercert()
        return ssl_info
    except Exception as e:
        print(f"Could not get SSL certificate for {hostname}: {e}")
        return None

def extract_subdomains_from_cert(cert):
    subdomains = []
    if not cert:
        return subdomains
    for san in cert.get('subjectAltName', []):
        if san[0] == 'DNS':
            subdomains.append(san[1])
    return subdomains

def ssl_extract(domain):
    cert = get_ssl_certificate(domain)
    subdomains = extract_subdomains_from_cert(cert)
    with open("validDomains.txt", "a") as validDomains:
        for url in subdomains:
            validDomains.write(f"{url}\n")
    return subdomains

def remove_duplicates():
    with open("validDomains.txt", 'r') as file:
        urls = set(file.readlines())
    string_list = ['85464', 'hewadgjyu', 'hjgfcdsaygh', 'yuhgwfe78uiu']

    urls = [line for line in urls if not any(s in line for s in string_list)]

    with open("validDomains.txt", 'w') as file:
        for url in sorted(urls):
            file.write(url)

def pull_URLS():
    with open("bad_requests.txt") as file:
        for line in file:
            urls = re.findall("'([\w.-]+\.[\w.-]+)'", line)
            if urls:
                urls = list(set(urls))
                with open("validDomains.txt", "a") as validDomains:
                    for url in urls:
                        validDomains.write(f"{url}\n")
                ##print(urls)

    remove_duplicates()



